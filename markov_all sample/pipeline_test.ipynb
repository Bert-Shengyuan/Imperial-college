{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2024-05-03T14:28:48.005530Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'spike train'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 26\u001B[0m\n\u001B[1;32m     17\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m Q\n\u001B[1;32m     18\u001B[0m \u001B[38;5;66;03m#choose \u001B[39;00m\n\u001B[1;32m     19\u001B[0m \n\u001B[1;32m     20\u001B[0m \u001B[38;5;66;03m# index = 0\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     23\u001B[0m \u001B[38;5;66;03m# mask_index = mask[:, :, int(mat_trigger[0 + index * 2, 0]):int(mat_trigger[1 + index * 2, 0])]\u001B[39;00m\n\u001B[1;32m     24\u001B[0m \u001B[38;5;66;03m#A_shuffled = dy_list_shuffled[i]\u001B[39;00m\n\u001B[0;32m---> 26\u001B[0m Spike_train \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mspike train\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     27\u001B[0m A \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mload(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdynamic connection\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     28\u001B[0m mask_index \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mload(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmask_index\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[0;32m~/miniconda/envs/cebra/lib/python3.8/site-packages/numpy/lib/npyio.py:405\u001B[0m, in \u001B[0;36mload\u001B[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001B[0m\n\u001B[1;32m    403\u001B[0m     own_fid \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m    404\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 405\u001B[0m     fid \u001B[38;5;241m=\u001B[39m stack\u001B[38;5;241m.\u001B[39menter_context(\u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mos_fspath\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mrb\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m)\n\u001B[1;32m    406\u001B[0m     own_fid \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m    408\u001B[0m \u001B[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001B[39;00m\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'spike train'"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "from scipy import sparse\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "def Connector(Q):\n",
    "    D = nx.to_networkx_graph(Q,create_using=nx.DiGraph())\n",
    "    Isolate_list=list(nx.isolates(D))\n",
    "    if len(Isolate_list)>0:\n",
    "        for i in Isolate_list:\n",
    "            if i==0:\n",
    "                Q[i+1,i]=0.0001\n",
    "            else:\n",
    "                Q[i-1,i]=0.0001\n",
    "    del D\n",
    "    return Q\n",
    "#choose \n",
    "\n",
    "# index = 0\n",
    "# Spike_train = neuron_spike[index]\n",
    "# A = dy_list[index]\n",
    "# mask_index = mask[:, :, int(mat_trigger[0 + index * 2, 0]):int(mat_trigger[1 + index * 2, 0])]\n",
    "#A_shuffled = dy_list_shuffled[i]\n",
    "\n",
    "Spike_train = np.load('spike train')\n",
    "A = np.load('dynamic connection')\n",
    "mask_index = np.load('mask_index')\n",
    "\n",
    "#KNN for sparse\n",
    "import networkx as nx\n",
    "from scipy import sparse\n",
    "\n",
    "N = A.shape[0]\n",
    "np.fill_diagonal(A, 0)\n",
    "# print(max(A[:,4]))\n",
    "# A=np.where(A > 0.09, 1, 0)\n",
    "k = 10\n",
    "\n",
    "# W.sort(reverse=True)\n",
    "B1 = np.zeros((N, N))\n",
    "for i in range(N):\n",
    "    W = sorted(A[i, :], reverse=True)\n",
    "    #     print( W[k])\n",
    "    B1[i, :] = np.where(A[i, :] > W[k], 1, 0)\n",
    "\n",
    "# B=np.multiply(B1,A)\n",
    "# print(W[k])\n",
    "# print(A[20,1:20])\n",
    "# print(B[20,1:20])\n",
    "\n",
    "\n",
    "C1 = np.zeros((N, N))\n",
    "for i in range(N):\n",
    "    W = sorted(A[:, i], reverse=True)\n",
    "    #     print( W[k])\n",
    "    C1[:, i] = np.where(A[:, i] > W[k], 1, 0)\n",
    "# C=np.multiply(C1,A)\n",
    "Q1 = B1 + C1\n",
    "Q2 = np.where(Q1 > .9, 1, 0)\n",
    "\n",
    "Q = np.multiply(Q2, A)\n",
    "# del A\n",
    "del B1\n",
    "del C1\n",
    "del Q1\n",
    "del Q2\n",
    "Connector(Q)\n",
    "D = nx.to_networkx_graph(Q, create_using=nx.DiGraph())\n",
    "D.number_of_edges()\n",
    "\n",
    "# adjacency = nx.to_scipy_sparse_array(A)\n",
    "import networkx as nx\n",
    "import scipy.sparse as sp\n",
    "import pygenstability as pgs\n",
    "import scipy.sparse as sp\n",
    "\n",
    "adjacency = sp.csr_matrix(Q)\n",
    "test = sp.csgraph.connected_components(adjacency)\n",
    "all_results = pgs.run(adjacency,\n",
    "                      min_scale=-1.5,\n",
    "                      max_scale=1.5,\n",
    "                      n_scale=200,\n",
    "                      n_tries = 600,\n",
    "                      constructor=\"directed\")\n",
    "all_results = pgs.identify_optimal_scales(all_results, kernel_size=14, window_size=14)\n",
    "_ = pgs.plot_scan(all_results)\n",
    "plt.show()\n",
    "# with open('/Users/sonmjack/Downloads/simon_paper/markov/fam1_Markov_list_age10_'+ str(index) +'.pkl', 'wb') as f:\n",
    "#     pickle.dump(all_results, f)\n",
    "    \n",
    "t_opt = 2\n",
    "selected_partitions = all_results['selected_partitions']\n",
    "Community = all_results['community_id'][selected_partitions[-t_opt]]\n",
    "import numpy as np\n",
    "import matplotlib.colors as mcolors\n",
    "import random\n",
    "\n",
    "Color_Code2 = [\"red\", \"orange\", \"pink\", \"olive\", \"cyan\", \"black\", \"yellow\", \"green\", \"brown\", \"gray\", \"tomato\",\n",
    "               \"violet\", \"yellowgreen\", \"y\", \"crimson\", \"darkgoldenrod\", \"darkmagenta\", \"indigo\", \"darkred\",\n",
    "               \"darkkhaki\", \"orangered\", 'aqua', 'aquamarine', 'azure', 'beige', 'bisque', 'black', 'blanchedalmond',\n",
    "               'blue', 'blueviolet', 'brown', 'burlywood', 'cadetblue', 'chartreuse', 'chocolate', 'coral',\n",
    "               'cornflowerblue', 'cornsilk', 'crimson', 'cyan', 'darkblue', 'darkcyan', 'darkgoldenrod', 'darkgray',\n",
    "               'darkkhaki', 'darkolivegreen', 'darkorange', 'darkorchid', 'darkred', 'darkseagreen', 'darkslateblue',\n",
    "               'darkslategray', 'darkturquoise', 'darkviolet', 'deeppink', 'deepskyblue', 'dimgray', 'dodgerblue',\n",
    "               'firebrick', 'floralwhite', 'forestgreen', 'fuchsia', 'gainsboro', 'ghostwhite', 'goldenrod',\n",
    "               'greenyellow', 'honeydew', 'hotpink', 'indianred', 'indigo', 'ivory', 'khaki', 'lavender',\n",
    "               'lavenderblush', 'lawngreen', 'lemonchiffon', 'lightblue', 'lightcoral', 'lightcyan',\n",
    "               'lightgoldenrodyellow', 'lightgreen', 'lightgray', 'lightpink', 'lightsalmon', 'lightseagreen',\n",
    "               'lightskyblue', 'lightslategray', 'lightsteelblue', 'lightyellow']\n",
    "\n",
    "list_color = []\n",
    "for color in mcolors.CSS4_COLORS:\n",
    "    list_color.append(color)\n",
    "random.shuffle(list_color)\n",
    "Color_Code1 = [*Color_Code2, *list_color]\n",
    "Color_Code = [*Color_Code1, *list_color]\n",
    "non_zero_indices_per_row = []\n",
    "for row in Spike_train:\n",
    "    non_zero_indices = np.where(row != 0)[0]\n",
    "    non_zero_indices_per_row.append(list(non_zero_indices))\n",
    "neuralData = []\n",
    "ColorCode = []\n",
    "\n",
    "it = 0\n",
    "Nodes = range(len(non_zero_indices_per_row))\n",
    "for i in range(max(Community) + 1):\n",
    "    for m, j in zip(Nodes, range(N)):\n",
    "        if Community[j] == i:\n",
    "            non_zero_indices_per_row[int(m)].sort()\n",
    "            neuralData.append(non_zero_indices_per_row[int(m)])\n",
    "            ColorCode.append(Color_Code[i])\n",
    "            # A_ordered_row[it,:]=Q[j,:]\n",
    "            it += 1\n",
    "# it=0\n",
    "# for i in range(max(Community)+1):\n",
    "#     for m,j in zip(Nodes,range(N)):\n",
    "#         if Community[j]==i:\n",
    "#             A_ordered[:,it]=A_ordered_row[:,j]\n",
    "#             it+=1\n",
    "plt.eventplot(neuralData, color=ColorCode)\n",
    "# plot.xlim([8000,9000])\n",
    "# plot.title('Spike raster plot')\n",
    "# plt.title(r\"%s,  $N_g=%d$\" % (data[l],max(Community)+1), fontweight ='bold',)\n",
    "# plt.title(r\"%s,  $S_%d$,  $N_c=%d$\" % (data[l],t_opt,max(Community)+1),fontsize = 22)\n",
    "plt.title(\"Reordered neural spike trains \" + f'N-{max(Community) + 1}')\n",
    "plt.xlabel('Time', fontsize=13)\n",
    "plt.ylabel('Rearranged Neuron ID', fontsize=13)\n",
    "plt.yticks(fontsize=13)\n",
    "plt.xticks(np.arange(0,20000, 5000), [str(int(i*5000/30)) for i in range(0, 4)],fontsize=13)\n",
    "plt.show()\n",
    "from matplotlib.colors import BoundaryNorm\n",
    "\n",
    "pic = np.zeros((512, 512))\n",
    "for i in range(mask_index.shape[2]):\n",
    "    index_row = np.where(mask_index[:, :, i] == True)[0]\n",
    "    index_con = np.where(mask_index[:, :, i] == True)[1]\n",
    "    for j in range(len(index_row)):\n",
    "        if Community[i] == 0:\n",
    "            pic[index_row[j], index_con[j]] = np.max(Community) + 1\n",
    "        else:\n",
    "            pic[index_row[j], index_con[j]] = Community[i]\n",
    "#cmap = sns.diverging_palette(220, 20, as_cmap=True)\n",
    "import seaborn as sns\n",
    "\n",
    "cmap = plt.get_cmap('tab10')  \n",
    "bounds = np.linspace(-0.5, 8.5, 10)  \n",
    "norm = BoundaryNorm(bounds, cmap.N)\n",
    "\n",
    "sns.heatmap(pic, cmap=cmap, norm=norm)\n",
    "plt.title('Community beasd on real data')\n",
    "plt.show()\n",
    "path = '/Users/sonmjack/Downloads/age10 result_fam1/wild_type_community.npy'\n",
    "np.save(path,Community)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Another part of hierarchical structure\n",
    "\n",
    "import matplotlib.colors as colors\n",
    "selected_partitions = all_results['selected_partitions']\n",
    "for k in range(len(selected_partitions)):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    Community = all_results['community_id'][selected_partitions[k]]\n",
    "    from matplotlib.colors import BoundaryNorm\n",
    "    \n",
    "    pic = np.zeros((512, 512))\n",
    "    for i in range(mask_index.shape[2]):\n",
    "        index_row = np.where(mask_index[:, :, i] == True)[0]\n",
    "        index_con = np.where(mask_index[:, :, i] == True)[1]\n",
    "        for j in range(len(index_row)):\n",
    "            if Community[i] == 0:\n",
    "                pic[index_row[j], index_con[j]] = np.max(Community) + 1\n",
    "            else:\n",
    "                pic[index_row[j], index_con[j]] = Community[i]\n",
    "    #cmap = sns.diverging_palette(220, 20, as_cmap=True)\n",
    "    import seaborn as sns\n",
    "    \n",
    "    tab10_colors = plt.cm.tab10(np.linspace(0, 1, 10))\n",
    "    extra_colors = plt.cm.Set3(np.linspace(0, 1, 12))  # 使用不同的colormap生成额外颜色\n",
    "    all_colors = np.vstack((tab10_colors, extra_colors[:12]))  # 只取额外颜色的前10种\n",
    "    custom_cmap = colors.ListedColormap(all_colors)\n",
    "    \n",
    "    \n",
    "    bounds = np.arange(0, 22) # 因为边界是从1开始，到12结束，所以需要加上13作为最后一个边界\n",
    "    #cmap = plt.cm.get_cmap('Spectral', len(bounds)-1) # 获取颜色映射，'viridis'可以替换成你喜欢的colormap\n",
    "    norm = BoundaryNorm(bounds, custom_cmap.N)\n",
    "    \n",
    "    \n",
    "    sns.heatmap(pic,  cmap=custom_cmap, norm=norm)\n",
    "    plt.title('Community beasd on real data')\n",
    "    plt.savefig('/Users/sonmjack/Downloads/age10 result_fam1/mask/' + 'dynamic distence_' +f'{index}_' + f'{k}'+'.jpg')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "import plotly.graph_objects as go  # pragma: no cover\n",
    "from plotly.offline import plot  # pragma: no cover\n",
    "import sys\n",
    "\n",
    "def plot_sankey(\n",
    "    all_results,\n",
    "    optimal_scales=True,\n",
    "    live=False,\n",
    "    filename=\"fig1.png\",\n",
    "    scale_index=None,\n",
    "):  # pragma: no cover\n",
    "    \"\"\"Plot Sankey diagram of communities accros scale (plotly only).\n",
    "    Args:\n",
    "        all_results (dict): results from run function\n",
    "        optimal_scales (bool): use optimal scales or not\n",
    "        live (bool): if True, interactive figure will appear in browser\n",
    "        filename (str): filename to save the plot\n",
    "        scale_index (bool): plot scale of indices\n",
    "    \"\"\"\n",
    "    sources = []\n",
    "    targets = []\n",
    "    values = []\n",
    "    shift = 0\n",
    "\n",
    "    if not scale_index:\n",
    "        all_results[\"community_id_reduced\"] = all_results[\"community_id\"]\n",
    "    else:\n",
    "        all_results[\"community_id_reduced\"] = [all_results[\"community_id\"][i] for i in scale_index]\n",
    "\n",
    "    community_ids = all_results[\"community_id_reduced\"]\n",
    "    if optimal_scales and (\"selected_partitions\" in all_results.keys()):\n",
    "        community_ids = [community_ids[u] for u in all_results[\"selected_partitions\"]]\n",
    "\n",
    " \n",
    "# Community=all_results['community_id'][selected_partitions[-t_opt]]\n",
    "\n",
    "    for i in range(len(community_ids) - 1):\n",
    "        community_source = np.array(community_ids[i])\n",
    "        community_target = np.array(community_ids[i + 1])\n",
    "        source_ids = set(community_source)\n",
    "        target_ids = set(community_target)\n",
    "#         print(target_ids)\n",
    "        for source in source_ids:\n",
    "            for target in target_ids:\n",
    "                value = sum(community_target[community_source == source] == target)\n",
    "#                 print(community_target[community_source == source] == target)\n",
    "                if value > 0:\n",
    "                    values.append(value)\n",
    "                    sources.append(source + shift)\n",
    "                    targets.append(target + len(source_ids) + shift)\n",
    "        shift += len(source_ids)\n",
    "\n",
    "    layout = go.Layout(autosize=True)\n",
    "    fig = go.Figure(\n",
    "        data=[\n",
    "            go.Sankey(\n",
    "                node={\n",
    "                    \"pad\": 1,\n",
    "                    \"thickness\": 1,\n",
    "                    \"line\": {\"color\": \"black\", \"width\": 0.0},\n",
    "                },\n",
    "                link={\"source\": sources, \"target\": targets, \"value\": values},\n",
    "            )\n",
    "        ],\n",
    "        layout=layout,\n",
    "    )\n",
    "\n",
    "    plot(fig, filename=filename)\n",
    "#     fig.update_layout(\n",
    "#         title=data,\n",
    "# #         xaxis_title=\"X Axis Title\",\n",
    "# #         yaxis_title=\"Y Axis Title\",\n",
    "# #         legend_title=\"Legend Title\",\n",
    "# #         font=dict(\n",
    "# #             family=\"Courier New, monospace\",\n",
    "# #             size=18,\n",
    "# #             color=\"RebeccaPurple\")\n",
    "#     )\n",
    "    fig.update_layout(showlegend=False)\n",
    "    fig.update_xaxes(visible=False)\n",
    "    fig.update_yaxes(visible=False)\n",
    "    \n",
    "    Scale_enumerate=[r'$S_{%s}$' % (len(community_ids)-i)  for i in range(len(community_ids))]\n",
    "    for x_coordinate, column_name in enumerate(Scale_enumerate):\n",
    "        fig.add_annotation(\n",
    "              x=x_coordinate,#Plotly recognizes 0-5 to be the x range.\n",
    "\n",
    "              y=1.075,#y value above 1 means above all nodes\n",
    "              xref=\"x\",\n",
    "              yref=\"paper\",\n",
    "              text=column_name,#Text\n",
    "              showarrow=False,\n",
    "              font=dict(\n",
    "                  family=\"Tahoma\",\n",
    "                  size=16,\n",
    "                  color=\"black\"\n",
    "                  ),\n",
    "              align=\"left\",\n",
    "              )\n",
    "    fig.write_image(filename)\n",
    "    \n",
    "#     if live:\n",
    "#         fig.show()\n",
    "\n",
    "#     return fig\n",
    "\n",
    "plot_sankey(\n",
    "    all_results,\n",
    "    optimal_scales=True,\n",
    "    live=False,\n",
    "    filename='Sankey.png' ,\n",
    "    scale_index=None,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
